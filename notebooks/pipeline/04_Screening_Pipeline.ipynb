{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Automated Screening Pipeline\n",
    "\n",
    "## AI ê¸°ë°˜ ì €íƒ„ì†Œ ì‹œë©˜íŠ¸ ëŒ€ì²´ì¬ ë°œê²¬ íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "**ëª©ì **: ì „ì²´ í›„ë³´ ì¬ë£Œì— ëŒ€í•œ ìë™í™” ìŠ¤í¬ë¦¬ë‹ ì‹¤í–‰\n",
    "\n",
    "---\n",
    "\n",
    "### íŒŒì´í”„ë¼ì¸ íë¦„\n",
    "\n",
    "```\n",
    "ê° í›„ë³´ ì¬ë£Œì— ëŒ€í•´:\n",
    "1. êµ¬ì¡° ìƒì„± (ì¡°ì„± ê¸°ë°˜)\n",
    "2. êµ¬ì¡° ìµœì í™” (CHGNet)\n",
    "3. ìˆ˜í™” ì‹œìŠ¤í…œ ìƒì„± (+10 Hâ‚‚O)\n",
    "4. MD ì‹œë®¬ë ˆì´ì…˜ (10 ps, 300K)\n",
    "5. ë¶„ì„ (Ca ìš©ì¶œ, Si CN, C-S-H)\n",
    "6. ì ìˆ˜ ê³„ì‚°\n",
    "```\n",
    "\n",
    "### ì˜ˆìƒ ì†Œìš” ì‹œê°„\n",
    "- í›„ë³´ë‹¹: ~15-20ë¶„ (GPU)\n",
    "- 16ê°œ í›„ë³´: ~4-5ì‹œê°„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent.parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import src\n",
    "from src.database import CandidateDatabase\n",
    "from src.pipeline import ScreeningPipeline, load_config\n",
    "from src.visualization import plot_screening_comparison, plot_evolution\n",
    "\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"âœ“ Modules loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU í™•ì¸\n",
    "import torch\n",
    "print(f\"\\nGPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì„¤ì • ë° ë°ì´í„° ë¡œë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¤ì • ë¡œë”©\n",
    "sim_config = load_config(\"simulation\")\n",
    "eval_config = load_config(\"evaluation\")\n",
    "\n",
    "print(\"Simulation Config:\")\n",
    "print(f\"  Optimization Fmax: {sim_config['optimization']['fmax']} eV/Ã…\")\n",
    "print(f\"  MD Duration: {sim_config['md_simulation']['screening']['duration_ps']} ps\")\n",
    "print(f\"  Temperature: {sim_config['md_simulation']['screening']['temperature_K']} K\")\n",
    "print(f\"  Water Molecules: {sim_config['hydration']['n_water']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í›„ë³´ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë”©\n",
    "db_path = src.DATA_DIR / \"candidates\" / \"candidates.json\"\n",
    "db = CandidateDatabase(db_path)\n",
    "\n",
    "print(f\"\\nCandidate Database: {len(db)} materials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤í¬ë¦¬ë‹ ëŒ€ìƒ ë¡œë”©\n",
    "screening_list_path = src.DATA_DIR / \"candidates\" / \"screening_list.json\"\n",
    "\n",
    "if screening_list_path.exists():\n",
    "    with open(screening_list_path, 'r') as f:\n",
    "        screening_list = json.load(f)\n",
    "    candidates = [db.get(name) for name in screening_list['candidates'] if db.get(name)]\n",
    "else:\n",
    "    candidates = list(db)\n",
    "\n",
    "print(f\"Screening Target: {len(candidates)} candidates\")\n",
    "print(\"\\nCandidate List:\")\n",
    "for i, c in enumerate(candidates, 1):\n",
    "    print(f\"  {i:2}. {c.name:<15} | Tier {c.tier} | COâ‚‚â†“ {c.co2_reduction}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì˜ˆìƒ ì‹œê°„ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆìƒ ì†Œìš” ì‹œê°„\n",
    "n_candidates = len(candidates)\n",
    "time_per_candidate = 15  # ë¶„ (GPU ê¸°ì¤€)\n",
    "total_time_min = n_candidates * time_per_candidate\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"ESTIMATED TIME\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"  Candidates: {n_candidates}\")\n",
    "print(f\"  Time per candidate: ~{time_per_candidate} min\")\n",
    "print(f\"  Total estimated: ~{total_time_min} min ({total_time_min/60:.1f} hours)\")\n",
    "print(f\"{'='*50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ìŠ¤í¬ë¦¬ë‹ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "\n",
    "âš ï¸ **ì£¼ì˜**: ì´ ì…€ì€ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤ (~4-5ì‹œê°„)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”\n",
    "pipeline = ScreeningPipeline(\n",
    "    config=sim_config,\n",
    "    output_dir=src.DATA_DIR / \"results\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Pipeline initialized\")\n",
    "print(f\"Output directory: {pipeline.output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤í¬ë¦¬ë‹ ì‹¤í–‰\n",
    "print(f\"\\nStarting screening at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "results = pipeline.run(candidates)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nTotal elapsed time: {elapsed/60:.1f} min ({elapsed/3600:.2f} hours)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ ì €ì¥\n",
    "results_path = pipeline.save_results(\"pipeline_screening_results.json\")\n",
    "print(f\"\\nâœ“ Results saved: {results_path}\")\n",
    "\n",
    "# ì—ëŸ¬ í™•ì¸\n",
    "if pipeline.errors:\n",
    "    print(f\"\\nâš ï¸ Errors occurred in {len(pipeline.errors)} candidates:\")\n",
    "    for name, error in pipeline.errors.items():\n",
    "        print(f\"  â€¢ {name}: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ìˆœìœ„ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìˆœìœ„ ê³„ì‚°\n",
    "rankings = pipeline.get_rankings()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCREENING RANKINGS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Rank':<6} {'Material':<15} {'Score':<8} {'Grade':<6} {'COâ‚‚â†“'}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for i, r in enumerate(rankings, 1):\n",
    "    print(f\"{i:<6} {r['name']:<15} {r['score']:<8.1f} {r['grade']:<6} {r['co2_reduction']}%\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë“±ê¸‰ë³„ ë¶„ë¥˜\n",
    "grades = {'A': [], 'B': [], 'C': [], 'D': []}\n",
    "for r in rankings:\n",
    "    grades[r['grade']].append(r['name'])\n",
    "\n",
    "print(\"\\nGrade Distribution:\")\n",
    "print(f\"  A (â‰¥70): {len(grades['A'])} - {', '.join(grades['A']) if grades['A'] else 'None'}\")\n",
    "print(f\"  B (â‰¥50): {len(grades['B'])} - {', '.join(grades['B']) if grades['B'] else 'None'}\")\n",
    "print(f\"  C (â‰¥30): {len(grades['C'])} - {', '.join(grades['C']) if grades['C'] else 'None'}\")\n",
    "print(f\"  D (<30): {len(grades['D'])} - {', '.join(grades['D']) if grades['D'] else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ìƒì„¸ ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ê²°ê³¼ í…Œì´ë¸” ìƒì„±\n",
    "table_data = []\n",
    "for name, result in results.items():\n",
    "    row = {\n",
    "        'Material': name,\n",
    "        'CO2_Reduction': result['co2_reduction'],\n",
    "        'Ca_Rate': result['analysis']['ca_leaching']['rate_per_ps'],\n",
    "        'Si_CN': result['analysis']['si_coordination']['mean_cn'],\n",
    "        'CSH_Pairs': result['analysis']['csh_formation']['max_pairs'],\n",
    "        'CO2_Score': result['score']['co2_score'],\n",
    "        'Ca_Score': result['score']['ca_score'],\n",
    "        'Si_Score': result['score']['si_score'],\n",
    "        'CSH_Score': result['score']['csh_score'],\n",
    "        'Total': result['score']['total_score'],\n",
    "        'Grade': result['score']['grade']\n",
    "    }\n",
    "    table_data.append(row)\n",
    "\n",
    "df = pd.DataFrame(table_data)\n",
    "df = df.sort_values('Total', ascending=False)\n",
    "\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVë¡œ ì €ì¥\n",
    "csv_path = src.DATA_DIR / \"results\" / \"pipeline_screening_summary.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nâœ“ CSV saved: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¹„êµ ì°¨íŠ¸\n",
    "fig1 = plot_screening_comparison(\n",
    "    results,\n",
    "    save_path=src.FIGURES_DIR / 'pipeline_screening_comparison.png'\n",
    ")\n",
    "plt.show()\n",
    "print(f\"\\nâœ“ Saved: pipeline_screening_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°„ ë³€í™” ê·¸ë˜í”„\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig2 = plot_evolution(\n",
    "    results,\n",
    "    save_path=src.FIGURES_DIR / 'pipeline_screening_evolution.png'\n",
    ")\n",
    "plt.show()\n",
    "print(f\"\\nâœ“ Saved: pipeline_screening_evolution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Top í›„ë³´ ì„ ë³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 í›„ë³´\n",
    "top_n = 5\n",
    "top_candidates = rankings[:top_n]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TOP {top_n} PROMISING CANDIDATES\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for i, r in enumerate(top_candidates, 1):\n",
    "    result = results[r['name']]\n",
    "    print(f\"\\n{i}. {r['name']}\")\n",
    "    print(f\"   Score: {r['score']:.1f}/100 (Grade {r['grade']})\")\n",
    "    print(f\"   COâ‚‚ Reduction: {r['co2_reduction']}%\")\n",
    "    print(f\"   Ca Leaching: {result['analysis']['ca_leaching']['rate_per_ps']:.3f} Ca/ps\")\n",
    "    print(f\"   Si Coordination: {result['analysis']['si_coordination']['mean_cn']:.2f}\")\n",
    "    print(f\"   C-S-H Pairs: {result['analysis']['csh_formation']['max_pairs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top í›„ë³´ ëª©ë¡ ì €ì¥\n",
    "top_list = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'total_screened': len(results),\n",
    "    'top_candidates': [r['name'] for r in top_candidates],\n",
    "    'details': top_candidates\n",
    "}\n",
    "\n",
    "top_path = src.DATA_DIR / \"results\" / \"top_candidates.json\"\n",
    "with open(top_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(top_list, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ“ Top candidates saved: {top_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SCREENING PIPELINE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "Duration: {elapsed/60:.1f} min ({elapsed/3600:.2f} hours)\n",
    "\n",
    "Results:\n",
    "  Total Candidates: {len(candidates)}\n",
    "  Successful: {len(results)}\n",
    "  Failed: {len(pipeline.errors)}\n",
    "\n",
    "Grade Distribution:\n",
    "  A (â‰¥70): {len(grades['A'])}\n",
    "  B (â‰¥50): {len(grades['B'])}\n",
    "  C (â‰¥30): {len(grades['C'])}\n",
    "  D (<30): {len(grades['D'])}\n",
    "\n",
    "Top 3 Candidates:\n",
    "\"\"\")\n",
    "\n",
    "for i, r in enumerate(rankings[:3], 1):\n",
    "    print(f\"  {i}. {r['name']} (Score: {r['score']:.1f}, COâ‚‚â†“ {r['co2_reduction']}%)\")\n",
    "\n",
    "print(f\"\"\"\n",
    "Files Generated:\n",
    "  â€¢ {results_path}\n",
    "  â€¢ {csv_path}\n",
    "  â€¢ {top_path}\n",
    "  â€¢ {src.FIGURES_DIR / 'pipeline_screening_comparison.png'}\n",
    "  â€¢ {src.FIGURES_DIR / 'pipeline_screening_evolution.png'}\n",
    "\n",
    "âœ… Screening Pipeline Complete!\n",
    "\"\"\")\n",
    "\n",
    "print(\"ğŸ“‹ Next Step: 05_Results_Analysis.ipynb (ìƒì„¸ ë¶„ì„)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ì™„ë£Œ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œ ìˆ˜í–‰í•œ ì‘ì—…:\n",
    "\n",
    "1. âœ… 16ê°œ í›„ë³´ ì¬ë£Œ ìë™ ìŠ¤í¬ë¦¬ë‹\n",
    "2. âœ… ê° ì¬ë£Œë³„ êµ¬ì¡° ìµœì í™” + MD ì‹œë®¬ë ˆì´ì…˜\n",
    "3. âœ… Ca ìš©ì¶œ, Si ë°°ìœ„ìˆ˜, C-S-H í˜•ì„± ë¶„ì„\n",
    "4. âœ… ì ìˆ˜ ê³„ì‚° ë° ìˆœìœ„í™”\n",
    "5. âœ… Top í›„ë³´ ì„ ë³„\n",
    "\n",
    "**ë‹¤ìŒ ë‹¨ê³„**: `05_Results_Analysis.ipynb`ì—ì„œ ê²°ê³¼ë¥¼ ìƒì„¸ ë¶„ì„í•˜ê³  ë…¼ë¬¸ìš© ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
